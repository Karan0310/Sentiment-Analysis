---
title: "Sentiment Analysis Using R"
author: "Karan Saxena"
date: "07/05/2021"
output: html_document
---
## About Sentiment Analysis
Sentiment Analysis is a process of extracting opinions that have different polarities. By polarities, I mean positive, negative or neutral. It is also known as opinion mining and polarity detection. With the help of sentiment analysis, you can find out the nature of opinion that is reflected in documents, websites, social media feed, etc. Sentiment Analysis is a type of classification where the data is classified into different classes. These classes can be binary in nature (positive or negative) or, they can have multiple classes (happy, sad, angry, etc.).

## Goal of this project
The aim of this project is to build a sentiment analysis model which will allow us to categorize words based on their sentiments, that is whether they are positive, negative and also the magnitude of it.

## Prepare environment
Install janeaustenr, tidytext, dplyr, ggplot2, tidyverse, tidyr, reshape2, wordcloud,stringr packages.
 ```{r}
 install.packages('janeasutenr')
 library(janeaustenr)
 
 install.packages('tidytext')
 library(tidytext)
 
 install.packages('dplyr')
 library(dplyr)
 
 install.packages('ggplot2')
 library(ggplot2)
 
 install.packages('tidyverse')
 library(tidyverse)
 
 install.packages('tidyr')
 library(tidyr)
 
 install.packages('reshape2')
 library(reshape2)
 
 install.packages('wordcloud')
 library(wordcloud)
 
 install.packages('stringr')
 library(stringr)
 
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

In order to build my project on sentiment analysis, I will make use of the tidytext package that comprises of sentiment lexicons that are present in the dataset of ‘sentiments’.
```{r}
library(tidytext)
sentiments
```
I will make use of three general purpose lexicons like –

1. AFINN
2. bing
3. loughran

These three lexicons make use of the unigrams. Unigrams are a type of n-gram model that consists of a sequence of 1 item, that is, a word collected from a given textual data. In the AFINN lexicon model scores the words in a range from -5 to 5. The increase in negativity corresponds the negative sentiment whereas an increase in positivity corresponds the positive one. The bing lexicon model on the other hand, classifies the sentiment into a binary category of negative or positive. And finally, the loughran model that performs analysis of the shareholder’s reports. In this project, I have made use of the bing lexicons to extract the sentiments out of the data.The lexicons can be retrieved using the get_sentiments() function.
```{r}
get_sentiments('bing')
```
### Performing Sentiment Analysis with the Inner Join
The janeaustenr package will provide the textual data in the form of books authored by the novelist Jane Austen. Tidytext will allow us to perform efficient text analysis on the data. I will convert the text of the books into a tidy format using unnest_tokens() function.
```{r}
tidy_data <- austen_books() %>%
 group_by(book) %>%
 mutate(linenumber = row_number(),
   chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]", 
                          ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
```

I have performed the tidy operation on the text such that each row contains a single word. I will now make use of the “bing” lexicon to and implement filter() over the words that correspond to joy. I will use the book Sense and Sensibility and derive its words to implement out sentiment analysis model.
```{r}
positive_senti <- get_sentiments("bing") %>%
 filter(sentiment == "positive")
tidy_data %>%
 filter(book == "Emma") %>%
 semi_join(positive_senti) %>%
 count(word, sort = TRUE)
```

From the above result, i observe many positive words like “good”, “happy”, “love” etc. In the next step, I will use spread() function to segregate the data into separate columns of positive and negative sentiments. I will then use the mutate() function to calculate the total sentiment, that is, the difference between positive and negative sentiment.
```{r}
bing <- get_sentiments("bing")
Emma_sentiment <- tidy_data %>%
 inner_join(bing) %>%
 count(book = "Emma" , index = linenumber %/% 80, sentiment) %>%
 spread(sentiment, n, fill = 0) %>%
 mutate(sentiment = positive - negative)
```

In the next step, I will visualize the words present in the book “Emma” based on their corrosponding positive and negative scores.
```{r}
ggplot(Emma_sentiment, aes(index, sentiment, fill = book)) +
 geom_bar(stat = "identity", show.legend = TRUE) +
 facet_wrap(~book, ncol = 2, scales = "free_x")
```

Now I've proceeded towards counting the most common positive and negative words that are present in the novel.
```{r}
counting_words <- tidy_data %>%
 inner_join(bing) %>%
 count(word, sentiment, sort = TRUE)
head(counting_words)
```

In the next step, I will perform visualization of the sentiment score. I will plot the scores along the axis that is labeled with both positive as well as negative words. I will use ggplot() function to visualize the data based on their scores.
```{r}
counting_words %>%
 filter(n > 150) %>%
 mutate(n = ifelse(sentiment == "negative", -n, n)) %>%
 mutate(word = reorder(word, n)) %>%
 ggplot(aes(word, n, fill = sentiment))+
 geom_col() +
 coord_flip() +
 labs(y = "Sentiment Score")
```

In the final visualization, I will create a wordcloud that will delineate the most recurring positive and negative words. In particular, I will use the comparision.cloud() function to plot both negative and positive words in a single wordcloud.
```{r}
tidy_data %>%
 inner_join(bing) %>%
 count(word, sentiment, sort = TRUE) %>%
 acast(word ~ sentiment, value.var = "n", fill = 0) %>%
 comparison.cloud(colors = c("red", "dark green"),
          max.words = 100)
```

## Summary
I went through the project of sentiment analysis in R. I learnt about the concept of sentiment analysis and implemented it over the dataset of Jane Austen’s books. I was able to delineate it through various visualizations after I performed data wrangling on the data. I used a lexical analyzer – ‘bing’ in this instance of the project. Furthermore, I have also represented the sentiment score through a plot and also made a visual report of wordcloud.
